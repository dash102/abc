{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        self.likelihood = likelihood\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, neighbors, target):\n",
    "    model.train()\n",
    "    model.likelihood.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    num_epochs = 200\n",
    "    losses = []\n",
    "    for i in range(num_epochs):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(neighbors)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, target)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        # print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "        #     i + 1, num_epochs, loss.item(),\n",
    "        #     model.covar_module.base_kernel.lengthscale.item(),\n",
    "        #     model.likelihood.noise.item()\n",
    "        # ))\n",
    "        optimizer.step()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, neighbors):\n",
    "    model.eval()\n",
    "    model.likelihood.eval()\n",
    "\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        hi_res_prediction = model.likelihood(model(neighbors))\n",
    "    return hi_res_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization helpers \n",
    "def _remove_axes(ax):\n",
    "    ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "def remove_axes(axes):\n",
    "    if len(axes.shape) == 2:\n",
    "        for ax1 in axes:\n",
    "            for ax in ax1:\n",
    "                _remove_axes(ax)\n",
    "    else:\n",
    "        for ax in axes:\n",
    "            _remove_axes(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patches(image, kernel_size, stride):\n",
    "    c = image.shape[1]\n",
    "    patches = nn.Unfold(kernel_size=kernel_size, stride=stride)(image)\n",
    "    b, image_size, grid_size = patches.shape\n",
    "    grid_width, grid_height = int(math.sqrt(grid_size)), int(math.sqrt(grid_size))\n",
    "    patches = patches.reshape(b, c, kernel_size, kernel_size, grid_width, grid_height)\n",
    "    return patches\n",
    "\n",
    "def get_model_inputs(patch):\n",
    "    target = []\n",
    "    neighbors = []\n",
    "    input_kernel_size = 3\n",
    "\n",
    "    b, c, patch_width, patch_height = patch.shape\n",
    "    training = nn.Unfold(kernel_size=input_kernel_size, stride=input_kernel_size)(patch)\n",
    "    training = training.reshape(1, c, input_kernel_size, input_kernel_size, patch_width // 3, patch_height // 3)\n",
    "    b, c, input_width, input_height, grid_width, grid_height = training.shape\n",
    "\n",
    "    for i in range(grid_width):\n",
    "        for j in range(grid_height):\n",
    "            y = training[:, :, 1, 1, i, j]\n",
    "            X_NL = training[:, :, :, :, i, j]\n",
    "            X_NL = X_NL.reshape(c, 1, 9).permute(1, 2, 0)\n",
    "            X_NL = torch.cat([X_NL[:, :4, :], X_NL[:, 5:, :]], dim=1)\n",
    "\n",
    "            target.append(y.squeeze())\n",
    "            neighbors.append(X_NL.squeeze())\n",
    "\n",
    "    target = torch.stack(target)\n",
    "    neighbors = torch.stack(neighbors)\n",
    "\n",
    "    return neighbors, target\n",
    "\n",
    "def get_neighbors_per_pixel(patch, kernel_size=3, stride=1, padding=1):\n",
    "    b, c, width, height = patch.shape\n",
    "    padded_patch = nn.ReflectionPad2d(padding)(patch)\n",
    "    neighbors = nn.Unfold(kernel_size=kernel_size, stride=stride)(padded_patch)\n",
    "    neighbors = neighbors.reshape(b, 9, (width + padding*2 - kernel_size + stride)**2)\n",
    "    neighbors = torch.cat([neighbors[:, :4, :], neighbors[:, 5:, :]], dim=1).permute(0, 2, 1)\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blending patches together to get final image\n",
    "\n",
    "def blend_patch(x0, x1, overlap, direction):\n",
    "    xh0, xw0 = x0.shape\n",
    "    xh1, xw1 = x1.shape\n",
    "    dim_to_overlap = xw0\n",
    "    other_dim = xh0\n",
    "    \n",
    "    if direction == 'v':\n",
    "        x0 = x0.permute(1, 0)\n",
    "        x1 = x1.permute(1, 0)\n",
    "        dim_to_overlap = xh0\n",
    "        other_dim = xw0\n",
    "\n",
    "    xramp0 = dim_to_overlap - overlap\n",
    "    xramp1 = 0\n",
    "\n",
    "    x00 = x0[:, :xramp0]\n",
    "    x01 = x0[:, xramp0:]\n",
    "\n",
    "    x11 = x1[:, :overlap]\n",
    "    x12 = x1[:, overlap:]\n",
    "\n",
    "    ramp0 = torch.linspace(1, 0, overlap).repeat((other_dim, 1))\n",
    "    ramp1 = 1 - ramp0\n",
    "\n",
    "    blend_mid = x01 * ramp0 + x11 * ramp1\n",
    "\n",
    "    blend = torch.cat([x00, blend_mid, x12], dim=1)\n",
    "    \n",
    "    if direction == 'v':\n",
    "        blend = blend.permute(1, 0)\n",
    "    return blend\n",
    "\n",
    "def blend(patches, overlap, dims):\n",
    "    h, w = dims\n",
    "    curr_blend = None\n",
    "    \n",
    "    for i in range(h):\n",
    "        row_blend = patches[i * w]\n",
    "        for j in range(1, w):\n",
    "            if w == 0 and h == 0:\n",
    "                continue\n",
    "            \n",
    "            idx = i * w + j\n",
    "\n",
    "            next_patch = patches[idx]\n",
    "            row_blend = blend_patch(row_blend, next_patch, overlap, 'h')\n",
    "\n",
    "        if curr_blend is None:\n",
    "            curr_blend = row_blend\n",
    "        else:\n",
    "            curr_blend = blend_patch(curr_blend, row_blend, overlap, 'v')\n",
    "    return curr_blend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsample implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss_grid(losses):\n",
    "    rows = len(losses)\n",
    "    cols = len(losses[0])\n",
    "\n",
    "    f, ax = plt.subplots(rows, cols, figsize=(cols, rows))\n",
    "    \n",
    "    for i in range(len(losses)):\n",
    "        for j in range(len(losses[0])):\n",
    "            ax[i, j].plot(losses[i][j])\n",
    "    remove_axes(ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(L, kernel_size, stride, scale_factor):\n",
    "    print(\"UPSAMPLING\")\n",
    "    patches_L = get_patches(L, kernel_size=kernel_size, stride=stride)\n",
    "    Hb = nn.Upsample(scale_factor=scale_factor, mode='bicubic')(L)\n",
    "    Hb_patches = get_patches(Hb, kernel_size * scale_factor, stride=stride * scale_factor)\n",
    "    upsample_losses = []\n",
    "    preds = []\n",
    "    for i in tqdm(range(patches_L.shape[-1])):\n",
    "        row_losses = []\n",
    "        for j in range(patches_L.shape[-1]):\n",
    "            patch_L = patches_L[..., i, j]\n",
    "            Xnl, y = get_model_inputs(patch_L)\n",
    "\n",
    "            likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "            model = ExactGPModel(Xnl, y, likelihood)\n",
    "            losses = train(model, Xnl, y)\n",
    "            \n",
    "            row_losses.append(losses)\n",
    "            \n",
    "            Hb_patch = Hb_patches[..., i, j]\n",
    "            inference = get_neighbors_per_pixel(Hb_patch)\n",
    "            observed_pred = predict(model, inference)\n",
    "            \n",
    "            s = int(math.sqrt(observed_pred.loc.shape[-1]))\n",
    "            preds.append(observed_pred.loc.reshape(s, s))\n",
    "        upsample_losses.append(row_losses)\n",
    "\n",
    "    s = Hb_patches.shape[-1]\n",
    "    blended = blend(preds, overlap=(kernel_size - stride) * scale_factor, dims=(s, s))\n",
    "    \n",
    "    show_loss_grid(upsample_losses)\n",
    "    \n",
    "    return blended.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deblur implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deblur(Hb, L, Lb, kernel_size, stride):\n",
    "    print(\"DEBLURRING\")\n",
    "    # partition downsampled_upsampled_low_res into n overlapped patches P_1, ..., P_n corresponding to those in low_res\n",
    "    hi_res_kernel_size = kernel_size * scale_factor\n",
    "    hi_res_stride = stride * scale_factor\n",
    "    low_res_patches, hi_res_patches = get_patches(Lb, kernel_size, stride), get_patches(Hb, hi_res_kernel_size, hi_res_stride)\n",
    "    batch_size, num_channels, patch_width, patch_height, grid_width, grid_height = low_res_patches.shape\n",
    "    deblur_losses = []\n",
    "    hi_res_predictions_patches = []\n",
    "    # for each patch, build y & X_NL and train a GPR model on them\n",
    "    for i in tqdm(range(grid_width)):\n",
    "        row_losses = []\n",
    "        for j in range(grid_height):\n",
    "            low_res_patch = low_res_patches[:, :, :, :, i, j]\n",
    "            hi_res_patch = hi_res_patches[:, :, :, :, i, j]\n",
    "            train_neighbors, train_target = get_model_inputs(low_res_patch)\n",
    "            test_neighbors = get_neighbors_per_pixel(hi_res_patch)\n",
    "\n",
    "            # train a GPR model M using {target, neighbors}\n",
    "            likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "            model = ExactGPModel(train_neighbors, train_target, likelihood)\n",
    "            row_losses.append(train(model, train_neighbors, train_target))\n",
    "\n",
    "            # for each pixel of hi_res_patch, get its eight neighbors and predict the new hi_res pixel\n",
    "            hi_res_prediction_patch = predict(model, test_neighbors)\n",
    "            hi_res_patch_width, hi_res_patch_height = hi_res_patch.shape[-2], hi_res_patch.shape[-1]\n",
    "            hi_res_predictions_patches.append(hi_res_prediction_patch.loc.squeeze().reshape(hi_res_patch_width, hi_res_patch_height))\n",
    "        deblur_losses.append(row_losses)\n",
    "\n",
    "    blended_H = blend(hi_res_predictions_patches, overlap=(hi_res_kernel_size - hi_res_stride), dims=(grid_width,grid_height))\n",
    "    \n",
    "    show_loss_grid(deblur_losses)\n",
    "    \n",
    "    return blended_H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRGPR on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = 10\n",
    "\n",
    "img = Image.open('./circles.png').convert(\"L\")\n",
    "L = T.Compose([\n",
    "    T.Resize(50),\n",
    "    T.ToTensor()\n",
    "])(img).unsqueeze(0)\n",
    "plt.imshow(L[0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 15\n",
    "stride = 5\n",
    "\n",
    "Hb = nn.Upsample(scale_factor=scale_factor, mode='bicubic')(L)\n",
    "H_tilde = upsample(L, kernel_size, stride, scale_factor=scale_factor)\n",
    "Lb = T.GaussianBlur(11)(H_tilde)\n",
    "Lb = F.interpolate(Lb.unsqueeze(0), scale_factor=(1/scale_factor), mode='bilinear', antialias=True)\n",
    "H = deblur(H_tilde.unsqueeze(0), L, Lb, kernel_size, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "ax[0].imshow(L.squeeze(), cmap='gray')\n",
    "ax[1].imshow(Hb.detach().numpy().squeeze(), cmap='gray')\n",
    "ax[2].imshow(H_tilde.detach().numpy().squeeze(), cmap='gray')\n",
    "ax[3].imshow(H.detach().numpy().squeeze(), cmap='gray')\n",
    "\n",
    "# ax[0].set_title(f'LR {L.squeeze().shape}')\n",
    "# ax[1].set_title(f'Bicubic {Hb.detach().numpy().squeeze().shape}')\n",
    "# ax[2].set_title(f'Upsampled {H_tilde.detach().numpy().squeeze().shape}')\n",
    "# ax[3].set_title(f'H {H.detach().numpy().squeeze().shape}')\n",
    "\n",
    "remove_axes(ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = H.detach().numpy().squeeze() - H_tilde.detach().numpy().squeeze()\n",
    "plt.imshow(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "percep",
   "language": "python",
   "name": "percep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
